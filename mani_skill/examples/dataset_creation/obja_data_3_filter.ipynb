{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54553f0d-4c82-4cdf-b3d2-20c25dd8854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from mani_skill.examples.objaverse_handler import SpokDatasetBuilder\n",
    "N_samples = 20_000\n",
    "spock_dataset = SpokDatasetBuilder(maximum_objects=N_samples)\n",
    "print(\"dataset size\", len(spock_dataset))\n",
    "scored_descr = spock_dataset.spok_root_path / \"clip_description.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be moved to the code that saves clip_description.jsonl\n",
    "import json\n",
    "scored_descr = spock_dataset.spok_root_path / \"clip_description.jsonl\"\n",
    "new_scored_descr = spock_dataset.spok_root_path / \"clip_description2.jsonl\"\n",
    "\n",
    "data = []\n",
    "uuids_seen = set()\n",
    "with open(scored_descr, \"r\") as f_obj:\n",
    "    for line in f_obj:\n",
    "        entry = json.loads(line)\n",
    "        if entry[\"uid\"] in uuids_seen:\n",
    "            print(\"removing duplicate\")\n",
    "            continue\n",
    "        data.append(entry)\n",
    "        uuids_seen.add(entry[\"uid\"])\n",
    "print(len(uuids_seen))\n",
    "\n",
    "for entry in data:\n",
    "    bbox = spock_dataset.get_bbox(entry[\"uid\"])\n",
    "    entry[\"bbox\"] = bbox.tolist()\n",
    "\n",
    "with open(new_scored_descr, \"w\") as f_obj:\n",
    "    for entry in data:\n",
    "        f_obj.write(json.dumps(entry) + \"\\n\")\n",
    "print(\"done saving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11a2b2-5880-4711-b868-a02a79446f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from heapq import nsmallest\n",
    "\n",
    "def top_n_above_threshold(scores, t, n):\n",
    "    return nsmallest(n, ((k, v) for k, v in scores.items() if v > t), key=lambda x: x[1])\n",
    "\n",
    "grayscale_scores = {}\n",
    "low_poly_scores = {}\n",
    "best_descr_scores = {}\n",
    "best_descr = {}\n",
    "\n",
    "data = []\n",
    "with open(scored_descr, \"r\") as f_obj:\n",
    "    for line in f_obj:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "print(\"dataset size\", len(data))\n",
    "for annotation in data:\n",
    "    # Parse each line as a JSON object\n",
    "    low_poly_scores[annotation[\"uid\"]] = annotation[\"quality\"][\"cartoon low-poly model\"]\n",
    "    grayscale_scores[annotation[\"uid\"]] = annotation[\"quality\"][\"grayscale image\"]\n",
    "    \n",
    "    short_descr_values = [v for k,v in annotation[\"description\"].items() if len(k.split()) < 4]\n",
    "    short_descr_text = [k for k,v in annotation[\"description\"].items() if len(k.split()) < 4]\n",
    "    \n",
    "    best_descr_scores[annotation[\"uid\"]] = max(short_descr_values)\n",
    "    best_descr[annotation[\"uid\"]] = short_descr_text[np.argmax(short_descr_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a3a81-34a4-465f-9ce9-dc288a747140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.hist(low_poly_scores.values(), bins=20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a6b144-cfb5-48be-928f-7902b864d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "#threshold_uids = top_n_above_threshold(grayscale_scores, -12, 20)\n",
    "threshold_uids = top_n_above_threshold(low_poly_scores, -10, 20)\n",
    "#threshold_uids = top_n_above_threshold(best_descr_scores, -3, 20)\n",
    "\n",
    "for uid, values in threshold_uids:\n",
    "    image_files = sorted( list((spock_dataset.spok_models_path / uid / \"blender_renders\" ).iterdir()))\n",
    "    image = Image.open(image_files[0])\n",
    "    print(best_descr[uid])\n",
    "    display(image)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c77a3d-9fe0-4631-aba8-6ea0c5585144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Literal, Optional\n",
    "\n",
    "def filter_func(annotation: Dict, t_best_descr=-3, t_low_poly=-10, t_grayscale=-12):\n",
    "        v_low_poly = annotation[\"quality\"][\"cartoon low-poly model\"]\n",
    "        v_grayscale = annotation[\"quality\"][\"grayscale image\"]\n",
    "        if v_low_poly > t_low_poly:\n",
    "            return False\n",
    "        if v_grayscale > t_grayscale:\n",
    "            return False\n",
    "        \n",
    "        short_descr_values = [v for k,v in annotation[\"description\"].items() if len(k.split()) < 4]\n",
    "        v_best_descr = max(short_descr_values)\n",
    "        if v_best_descr < t_best_descr:\n",
    "            return False\n",
    "\n",
    "        short_descr_text = [k for k,v in annotation[\"description\"].items() if len(k.split()) < 4]\n",
    "        best_descr = short_descr_text[np.argmax(short_descr_values)]\n",
    "        blacklist_words = set((\"stone\", \"rock\", \"figurine\", \"ring\"))\n",
    "        if set(best_descr.split()).intersection(blacklist_words):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "print(\"dataset size:\", len(data))\n",
    "data_filtered = [annotation for annotation in data if filter_func(annotation)]\n",
    "print(\"dataset size (filtered):\", len(data_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d7642-951e-45a9-a762-de8b6e92e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "words = []\n",
    "for annotation in data_filtered:\n",
    "    words.extend(best_descr[annotation[\"uid\"]].split())\n",
    "Counter(words).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc74ee-f201-4027-b3ee-6192946c2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "n = 2\n",
    "for annotation in random.sample(data_filtered, min(n, len(data_filtered))):\n",
    "    uid = annotation[\"uid\"]\n",
    "    image_files = sorted(list((spock_dataset.spok_models_path / uid / \"blender_renders\" ).iterdir()))\n",
    "    image = Image.open(image_files[0])\n",
    "    print(best_descr[uid])\n",
    "    display(image)\n",
    "\n",
    "# uid = \"3239828896624cdaae337e1b8b5ca78f\"\n",
    "# image_files = sorted(list((spock_dataset.spok_models_path / uid / \"blender_renders\" ).iterdir()))\n",
    "# image = Image.open(image_files[0])\n",
    "# print(best_descr[uid])\n",
    "# display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476241d5-ee8b-4f62-a3db-db5b1ede4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "Counter([best_descr[annotation[\"uid\"]] for annotation in data_filtered]).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57f751-e678-4bac-bcf6-e10caeaae57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
