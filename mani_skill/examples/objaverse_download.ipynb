{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zn7g17hc3ADi"
   },
   "source": [
    "# Objaverse Downloading Script\n",
    "\n",
    "Objaverse-XL is a Universe of 10M+ 3D Objects.\n",
    "It is hosted on ðŸ¤—[Hugging Face](https://huggingface.co/datasets/allenai/objaverse-xl) and includes a [Python API on GitHub](https://github.com/allenai/objaverse-xl).\n",
    "\n",
    "It's a bit difficult to get a dataset which is compatible for manipulation. There are a few subsets of Objaverse with additional annotations, such a Spock.\n",
    "\n",
    "See Spock [Readme](https://github.com/allenai/spoc-robot-training) and [notebook example](https://github.com/allenai/spoc-robot-training/blob/main/how_to_use_data.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export OBJAVERSE_PATH=\"/data/lmbraid19/argusm/datasets/spok/\"\n",
    "# !python -m objathor.dataset.download_annotations --version 2023_07_28 --path $OBJAVERSE_PATH\n",
    "# !python -m objathor.dataset.download_assets --version 2023_07_28 --path $OBJAVERSE_PATH\n",
    "!pip install objaverse --upgrade --quiet\n",
    "!pip install compress_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "wLB-BPGqGi2e",
    "outputId": "847c0b41-a4f7-413b-9af2-c0746ff64205"
   },
   "outputs": [],
   "source": [
    "import objaverse\n",
    "objaverse.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spock Annotations\n",
    "The rest of the cells are from the old tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint \n",
    "import compress_json\n",
    "import objaverse\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "#OBJAVERSE_ANNOTATIONS_PATH = \"/data/lmbraid19/argusm/datasets/spok/2023_07_28/annotations.json.gz\"\n",
    "#annotations_spock = compress_json.load(OBJAVERSE_ANNOTATIONS_PATH)\n",
    "\n",
    "OBJAVERSE_ANNOTATIONS_PATH = \"/data/lmbraid19/argusm/datasets/spok/2025_01_30/annotations.json\"\n",
    "with open(OBJAVERSE_ANNOTATIONS_PATH) as f_obj:\n",
    "    annotations_spock = json.load(f_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "print(\"annotated examples\", len(annotations_spock))\n",
    "annotations_spock_full = annotations_spock\n",
    "annotations_spock = dict(islice(annotations_spock.items(), 5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "Objaverse has a ton of assets, so let's filter them a bit for sanity:\n",
    "1. using existing annotation: `CanPickup`, `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "can_pickups = []\n",
    "for i, (k,v) in enumerate(iter(annotations_spock.items())):\n",
    "    try:\n",
    "        can_pickup = v[\"thor_metadata\"][\"assetMetadata\"][\"primaryProperty\"] == \"CanPickup\"\n",
    "    except:\n",
    "        can_pickup = False\n",
    "    can_pickups.append(can_pickup)\n",
    "    #print(v['description'], v[\"receptacle\"], )\n",
    "print(np.mean(can_pickups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemma_set = set([v['most_specific_lemma'] for k,v in annotations_spock.items()])\n",
    "#cat_set = set([v['category'] for k,v in annotations_spock.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metadata = True\n",
    "if print_metadata:\n",
    "    # print the metadata\n",
    "    #uid = '9d17119cc0f041e39b2a11211a677366'\n",
    "    uid = '584ce7acb3384c36bf252fde72063a56'\n",
    "    pp.pprint(annotations_spock_full[uid])\n",
    "    ann = objaverse.load_annotations([uid])\n",
    "    pp.pprint(ann[uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_with_largest_size_above_min(thubnail_image_data, min_size=448):\n",
    "    valid_entries = [\n",
    "        (index, entry['size']) \n",
    "        for index, entry in enumerate(thubnail_image_data) \n",
    "        if max(entry['width'], entry['height']) >= min_size\n",
    "    ]\n",
    "    if not valid_entries:\n",
    "        return 0 # No valid entries found\n",
    "    return min(valid_entries, key=lambda x: x[1])[0]\n",
    "\n",
    "#key = '584ce7acb3384c36bf252fde72063a56'\n",
    "#ann = objaverse.load_annotations([key])\n",
    "#tmp = ann[key]['thumbnails']['images']\n",
    "#print(find_index_with_largest_size_above_min(tmp))\n",
    "#tmp\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "OBJAVERSE_THUMBNAIL_PATH = Path('/data/lmbraid19/argusm/datasets/spok/thumbnails')\n",
    "\n",
    "for i, (key, value) in tqdm(enumerate(annotations_spock.items()),total=len(annotations_spock)):\n",
    "    obj_anno = annotations_spock[key]\n",
    "    if \"thor_metadata\" not in obj_anno:\n",
    "        continue\n",
    "        \n",
    "    bbox = obj_anno['thor_metadata']['assetMetadata']['boundingBox']\n",
    "    extents = {\n",
    "        'x': bbox['max']['x'] - bbox['min']['x'],\n",
    "        'y': bbox['max']['y'] - bbox['min']['y'],\n",
    "        'z': bbox['max']['z'] - bbox['min']['z']\n",
    "    }\n",
    "    extents = [extents[d]*100 for d in list('xyz')]\n",
    "    if min(extents) < 2 or max(extents) > 50:\n",
    "        continue\n",
    "        \n",
    "    ann = objaverse.load_annotations([key])\n",
    "    thumbnail_image_data = ann[key]['thumbnails']['images']\n",
    "    i = find_index_with_largest_size_above_min(thumbnail_image_data)\n",
    "    url = thumbnail_image_data[i]['url']\n",
    "    fn = OBJAVERSE_THUMBNAIL_PATH / f\"{key}{Path(url).suffix}\"\n",
    "    if fn.is_file():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)  # Use streaming for large files\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "    except requests.exceptions.HTTPError:\n",
    "        continue\n",
    "    \n",
    "    with open(fn, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):  # Write in chunks\n",
    "            file.write(chunk)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Example Images with Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spock_metadata(uid, metadata, extents):\n",
    "    print(\"uid\", uid)\n",
    "    print(\"category\", metadata[\"category\"])\n",
    "    print(\"descrip\", metadata[\"description\"])\n",
    "    #print(\"descr-auto\", metadata[\"description_auto\"])\n",
    "    print(\"scale\", metadata[\"scale\"], \"extents\",\" \".join([f\"{d:.0f}\" for d in extents]) + \" cm\")\n",
    "\n",
    "def get_extents(anno_spock):\n",
    "    bbox = anno_spock['thor_metadata']['assetMetadata']['boundingBox']\n",
    "    extents = {\n",
    "        'x': bbox['max']['x'] - bbox['min']['x'],\n",
    "        'y': bbox['max']['y'] - bbox['min']['y'],\n",
    "        'z': bbox['max']['z'] - bbox['min']['z']\n",
    "    }\n",
    "    extents = [extents[d]*100 for d in list('xyz')]\n",
    "    return extents\n",
    "\n",
    "count = 0\n",
    "for i, (key, value) in enumerate(annotations_spock.items()):\n",
    "    anno_s = annotations_spock[key]\n",
    "    if \"thor_metadata\" not in anno_s:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        extents = get_extents(anno_s)\n",
    "    except KeyError:\n",
    "        continue\n",
    "    \n",
    "    if min(extents) < 2 or max(extents) > 50:\n",
    "        continue\n",
    "        \n",
    "    ann = objaverse.load_annotations([key])\n",
    "    url = ann[key]['thumbnails']['images'][0]['url']\n",
    "    print_spock_metadata(key, anno_s, extents)\n",
    "    display(Image(url=url, width=512))\n",
    "    print()\n",
    "\n",
    "    count += 1\n",
    "    #results = objaverse.load_objects([key])\n",
    "    if i > 100:\n",
    "        break\n",
    "\n",
    "print(\"pass rate\", count, \"/\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select objects and download\n",
    "\n",
    "This is done manually for now, but it should happen automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_uids = ['412ed49af0644f30bae822d29afbb066',\n",
    "'93128128f8f848d8bd261f6c1f763a53',\n",
    "'b5c9d06f19be4c92a1708515f6655573',\n",
    "'584ce7acb3384c36bf252fde72063a56',\n",
    "'2796ec7a4a324d9e988d95d88bb6f1e2',\n",
    "'005a246f8c304e77b27cf11cd53ff4ed',\n",
    "'013176cfbc8145a0b10c3191ac265e8b',\n",
    "'00bfa4e5862d4d4b89f9bcf06d2a19e4',\n",
    "'088c1883e07e4946956488171e3a06bf',\n",
    "'0364ab96f338493c972248102b462aa4',\n",
    "'ff6c46b1e8f847ecadd5c95805f415c6']\n",
    "\n",
    "res = objaverse.load_objects(good_uids)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_uids = ['b5c9d06f19be4c92a1708515f6655573','412ed49af0644f30bae822d29afbb066']\n",
    "\n",
    "count = 0\n",
    "for i, key in enumerate(good_uids):\n",
    "    anno_s = annotations_spock[key]\n",
    "    if \"thor_metadata\" not in anno_s:\n",
    "        continue\n",
    "    \n",
    "    extents = get_extents(anno_s)\n",
    "    if min(extents) < 2 or max(extents) > 50:\n",
    "        continue\n",
    "        \n",
    "    ann = objaverse.load_annotations([key])\n",
    "    url = ann[key]['thumbnails']['images'][0]['url']\n",
    "    print_spock_metadata(key, anno_s, extents)\n",
    "    display(Image(url=url, width=512))\n",
    "    print()\n",
    "\n",
    "    count += 1\n",
    "    #results = objaverse.load_objects([key])\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render in Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gymnasium as gym\n",
    "import mani_skill.examples.clevr_env  # do import to register env, not used otherwise\n",
    "from mani_skill.envs.sapien_env import BaseEnv\n",
    "from mani_skill.examples.gen_dataset import Args, reset_random\n",
    "import matplotlib.pyplot as plt \n",
    "    \n",
    "args = Args()\n",
    "args.env_id = \"ClevrMove-v1\"\n",
    "#args.shader = \"rt-fast\" or \"rt\"\n",
    "#args.seed = [42,]\n",
    "reset_random(args)\n",
    "\n",
    "vis = False\n",
    "env: BaseEnv = gym.make(\n",
    "    args.env_id,\n",
    "    obs_mode=args.obs_mode,\n",
    "    reward_mode=args.reward_mode,\n",
    "    control_mode=args.control_mode,\n",
    "    render_mode=args.render_mode,\n",
    "    sensor_configs=dict(shader_pack=args.shader),\n",
    "    human_render_camera_configs=dict(shader_pack=args.shader),\n",
    "    viewer_camera_configs=dict(shader_pack=args.shader),\n",
    "    num_envs=args.num_envs,\n",
    "    sim_backend=args.sim_backend,\n",
    "    parallel_in_single_scene=False,\n",
    "    robot_uids=\"panda_wristcam\",\n",
    "    object_dataset=\"objaverse\",\n",
    "    scene_dataset=\"Table\",\n",
    "    # **args.env_kwargs\n",
    ")\n",
    "\n",
    "for i in range(10**6):\n",
    "    obs, _ = env.reset(seed=args.seed[0], options=dict(reconfigure=True))\n",
    "    if args.seed is not None:\n",
    "        env.action_space.seed(args.seed[0])\n",
    "    if vis and args.render_mode is not None:\n",
    "        viewer = env.render()\n",
    "        if isinstance(viewer, sapien.utils.Viewer):\n",
    "            viewer.paused = args.pause\n",
    "        env.render()\n",
    "    else:\n",
    "        env.render()\n",
    "    \n",
    "    # get before image\n",
    "    images = env.base_env.scene.get_human_render_camera_images('render_camera')\n",
    "    print(i)\n",
    "    plt.imshow(images['render_camera'][0].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "    if i > 0:\n",
    "        break\n",
    "    reset_random(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Old-Stuff] Load all objaverse UIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = objaverse.load_uids()\n",
    "len(uids), type(uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a couple of minutes\n",
    "annotations = objaverse.load_annotations(uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pprint \n",
    "for i, (key, annotation) in enumerate(annotations.items()):\n",
    "    pp.pprint(annotation)\n",
    "    #print(annotation[\"description\"])\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Old-Stuff] LIVS Annotation Stuff\n",
    "\n",
    "LVIS was this subset of objaverse which hand proper annotations. I was looking at it before I found the Spock annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3k9kk352jAcE"
   },
   "outputs": [],
   "source": [
    "import objaverse\n",
    "counts = [(k,len(v)) for k,v in annotations2.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select N_categories objects\n",
    "N_categories = 100\n",
    "print(len(counts))\n",
    "sum([v for k, v in counts])\n",
    "collection = []\n",
    "i = 0\n",
    "for i, (k, v) in enumerate(annotations2.items()):\n",
    "  if i >= N_categories:\n",
    "    break\n",
    "  collection.append(v[0])\n",
    "print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = objaverse.load_objects(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object loading code, LVIS names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glb_downloaded = [x.stem for x in glb_files]\n",
    "# glb_downloaded_set = set(glb_downloaded)            \n",
    "# anno_path = objaverse_folder / \"lvis-annotations.json.gz\"\n",
    "# import gzip, json\n",
    "# with gzip.open(anno_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "#     lvis_annotations = json.load(f)\n",
    "# mapping = {}\n",
    "# for category, items in lvis_annotations.items():\n",
    "#     for index, item in enumerate(items, start=1):  # Use 1-based indexing\n",
    "#         if item not in glb_downloaded_set:\n",
    "#             continue\n",
    "#         mapping[f\"{category}-{index}\"] = glb_files[glb_downloaded.index(item)]\n",
    "# self.objaverse_model_ids = list(mapping.keys())\n",
    "# self.objaverse_files = mapping"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "paligemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
